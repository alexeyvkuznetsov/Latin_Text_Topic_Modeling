install.packages(c("aplpack", "foreach", "iterators", "magick", "quanteda", "quantreg", "Rcpp", "reticulate", "sf", "stopwords", "testthat", "tidytext", "xml2"))
library(Rcmdr)
install.packages(c("haven", "Hmisc", "openxlsx", "plotly", "sp"))
install.packages(c("BH", "bit", "cli", "fansi", "farver", "fpc", "hms", "knitr", "leaps", "multcomp", "mvtnorm", "prabclus", "prettyunits", "psych", "qdap", "RcmdrMisc", "RCurl", "Rttf2pt1", "stringi", "tinytex", "wordspace", "xfun", "XML", "zoo"))
install.packages(c("biclust", "bit", "callr", "checkmate", "chron", "dendextend", "digest", "DT", "FactoMineR", "foreach", "fpc", "ggpubr", "ggraph", "hexbin", "Hmisc", "jsonlite", "knitr", "mapproj", "mime", "mnormt", "plotly", "processx", "ps", "RcppArmadillo", "RcppProgress", "rgl", "rstudioapi", "styler", "svglite", "xlsx"))
install.packages("xlsx")
install.packages(c("remotes", "xlsx"))
install.packages(c("ggm", "xlsx"))
install.packages("xlsx")
install.packages(c("covr", "dplyr", "fs", "ggplot2", "lifecycle", "modeltools", "survival", "textdata"))
install.packages(c("Cairo", "car", "crosstalk", "diffobj", "ggraph", "ggrepel", "glue", "graphlayouts", "Hmisc", "igraph", "iotools", "ISOcodes", "lgr", "matrixStats", "nloptr", "quanteda", "rapidjsonr", "Rcpp", "RcppParallel", "roxygen2", "shiny", "svs", "units", "vctrs", "xml2"))
install.packages("igraph")
install.packages(c("arm", "backports", "bigrquery", "broom", "Cairo", "circlize", "dbplyr", "devtools"))
install.packages(c("float", "gargle", "gender", "ggpubr", "git2r"))
install.packages(c("tidyr", "tidyselect", "tidytext", "tinytex", "topicmodels", "vctrs", "withr", "xfun", "xml2", "zoo"))
install.packages("topicmodels")
install.packages(c("modelr", "multcomp", "openxlsx", "pillar", "pkgbuild", "plotrix", "ps", "purrr"))
install.packages("installr")
library(installr)
updateR()
updateR()
install.packages(c("textmineR", "tm", "udpipe"))
install.packages(c("backports", "glue", "maptools"))
install.packages("stm")
install.packages("LSAfun")
install.packages(c("backports", "glmnet", "glue", "maptools"))
install.packages("ggcorrplot")
library(dendextend)
require("igraph")
install.packages(c("backports", "ellipsis", "glmnet", "glue", "maptools", "RcppArmadillo", "RhpcBLASctl"))
install.packages(c("backports", "ellipsis", "glmnet", "RcppArmadillo", "RhpcBLASctl"))
install.packages(c("backports", "car", "carData", "ggraph", "RcppArmadillo", "RhpcBLASctl", "sp", "tidyr", "xfun"))
install.packages(c("backports", "ggraph"))
install.packages("backports")
install.packages(c("backports", "broom", "fs", "ggforce", "ggplot2", "ggpubr", "glmnet", "htmltools", "isoband", "jsonlite", "knitr", "nloptr", "openssl", "pillar", "pkgbuild", "processx", "quanteda", "quantreg", "Rcpp", "RcppArmadillo", "RcppParallel", "rlang", "rstatix", "shiny", "tibble", "tidytext", "vctrs", "xfun"))
install.packages(c("backports", "fs", "ggforce", "RcppArmadillo", "rlang", "vctrs"))
install.packages(c("backports", "RcppArmadillo", "rlang", "vctrs"))
install.packages(c("backports", "car", "data.table", "dplyr", "fs", "httr", "maptools", "ps", "quanteda", "RcppArmadillo", "rlang", "sys", "tidyr", "vctrs", "xfun", "zip"))
install.packages(c("backports", "maptools"))
install.packages(c("backports", "maptools"))
install.packages(c("backports", "callr", "conquer", "cowplot", "dendextend", "glue", "jsonlite", "maptools", "processx", "quantreg", "RcppArmadillo", "stringi", "tidyr", "vctrs", "xfun", "zip"))
install.packages("word2vec")
install.packages(c("jsonlite", "quantreg", "stringi", "xfun"))
library(udpipe)
x <- udpipe("The package provides a dependency parsers built on data from universaldependencies.org", "english")
install.packages("textplot")
library(udpipe)
x <- udpipe("The package provides a dependency parsers built on data from universaldependencies.org", "english")
install.packages(c("backports", "broom", "callr", "car", "cli", "clipr", "coda", "cpp11", "data.table", "digest", "foreach", "htmlwidgets", "igraph", "iterators", "jsonlite", "knitr", "labeling", "lgr", "lme4", "matrixStats", "network", "NLP", "openssl", "openxlsx", "ps", "quanteda", "quantreg", "RcppArmadillo", "readr", "rlang", "shape", "sna", "sp", "statmod", "statnet.common", "stm", "stringi", "tibble", "tidytext", "udpipe", "usethis", "withr", "word2vec", "xfun"))
library(udpipe)
x <- udpipe("The package provides a dependency parsers built on data from universaldependencies.org", "english")
library(udpipe)
library(udpipe)
install.packages(c("backports", "data.table", "gh", "htmlwidgets", "hunspell", "isoband", "ISOcodes", "jsonlite", "lme4", "processx", "ps", "rgl", "rlang", "slam", "stopwords", "syuzhet", "udpipe", "usethis", "word2vec"))
install.packages(c("backports", "hunspell", "jsonlite", "udpipe"))
install.packages(c("backports", "hunspell", "jsonlite", "udpipe"))
install.packages(c("backports", "hunspell", "jsonlite", "udpipe"))
install.packages("udpipe")
install.packages("udpipe")
install.packages("installr")
library(installr)
updateR()
install.packages("backports")
install.packages("hunspell")
install.packages("udpipe")
install.packages(c("backports", "hunspell", "jsonlite", "udpipe"))
setwd("D:/GitHub/Latin_Text_Topic_Modeling/")
library(stringr)
library(dplyr)
library(tidytext)
library(quanteda)
data("data_corpus_inaugural", package = "quanteda")
inaugural_counts <- tidy(data_corpus_inaugural) %>%
mutate(document = str_c(Year, President, sep = "_")) %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
count(document, word, sort = TRUE)
inaugural_dfm <- inaugural_counts %>%
cast_dfm(document = document, term = word, value = n)
library(furrr)
plan(multiprocess)
models <- tibble(K = 2:6) %>%
mutate(topic_model = future_map(K, ~ stm(inaugural_dfm,
init.type = "Spectral",
K = .,
verbose = FALSE)))
??stm
library(topicmodels)
models <- tibble(K = 2:6) %>%
mutate(topic_model = future_map(K, ~ stm(inaugural_dfm,
init.type = "Spectral",
K = .,
verbose = FALSE)))
library(stm)
models <- tibble(K = 2:6) %>%
mutate(topic_model = future_map(K, ~ stm(inaugural_dfm,
init.type = "Spectral",
K = .,
verbose = FALSE)))
heldout <- make.heldout(inaugural_dfm)
k_result <- models %>%
mutate(exclusivity        = map(topic_model, exclusivity),
semantic_coherence = map(topic_model, semanticCoherence, inaugural_dfm),
eval_heldout       = map(topic_model, eval.heldout, heldout$missing),
residual           = map(topic_model, checkResiduals, inaugural_dfm),
bound              = map_dbl(topic_model, function(x) max(x$convergence$bound)),
lfact              = map_dbl(topic_model, function(x) lfactorial(x$settings$dim$K)),
lbound             = bound + lfact,
iterations         = map_dbl(topic_model, function(x) length(x$convergence$bound)))
?map
# clean current workspace
rm(list=ls(all=T))
setwd("D:/GitHub/Latin_Text_Topic_Modeling/")
library(stringr)
library(dplyr)
library(tidytext)
library(quanteda)
data("data_corpus_inaugural", package = "quanteda")
inaugural_counts <- tidy(data_corpus_inaugural) %>%
mutate(document = str_c(Year, President, sep = "_")) %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
count(document, word, sort = TRUE)
View(inaugural_counts)
inaugural_dfm <- inaugural_counts %>%
cast_dfm(document = document, term = word, value = n)
View(inaugural_counts)
View(inaugural_dfm)
library(furrr)
plan(multiprocess)
library(stm)
models <- tibble(K = 2:6) %>%
mutate(topic_model = future_map(K, ~ stm(inaugural_dfm,
init.type = "Spectral",
K = .,
verbose = FALSE)))
heldout <- make.heldout(inaugural_dfm)
k_result <- models %>%
mutate(exclusivity        = map(topic_model, exclusivity),
semantic_coherence = map(topic_model, semanticCoherence, inaugural_dfm),
eval_heldout       = map(topic_model, eval.heldout, heldout$missing),
residual           = map(topic_model, checkResiduals, inaugural_dfm),
bound              = map_dbl(topic_model, function(x) max(x$convergence$bound)),
lfact              = map_dbl(topic_model, function(x) lfactorial(x$settings$dim$K)),
lbound             = bound + lfact,
iterations         = map_dbl(topic_model, function(x) length(x$convergence$bound)))
??map
??"map"
library(ggplot2)
k_result <- models %>%
mutate(exclusivity        = map(topic_model, exclusivity),
semantic_coherence = map(topic_model, semanticCoherence, inaugural_dfm),
eval_heldout       = map(topic_model, eval.heldout, heldout$missing),
residual           = map(topic_model, checkResiduals, inaugural_dfm),
bound              = map_dbl(topic_model, function(x) max(x$convergence$bound)),
lfact              = map_dbl(topic_model, function(x) lfactorial(x$settings$dim$K)),
lbound             = bound + lfact,
iterations         = map_dbl(topic_model, function(x) length(x$convergence$bound)))
library(ggraph)
k_result <- models %>%
mutate(exclusivity        = map(topic_model, exclusivity),
semantic_coherence = map(topic_model, semanticCoherence, inaugural_dfm),
eval_heldout       = map(topic_model, eval.heldout, heldout$missing),
residual           = map(topic_model, checkResiduals, inaugural_dfm),
bound              = map_dbl(topic_model, function(x) max(x$convergence$bound)),
lfact              = map_dbl(topic_model, function(x) lfactorial(x$settings$dim$K)),
lbound             = bound + lfact,
iterations         = map_dbl(topic_model, function(x) length(x$convergence$bound)))
k_result %>%
transmute(K,
`Lower bound`         = lbound,
Residuals             = map_dbl(residual, "dispersion"),
`Semantic coherence`  = map_dbl(semantic_coherence, mean),
`Held-out likelihood` = map_dbl(eval_heldout, "expected.heldout")) %>%
pivot_longer(-K, names_to = "metrics", values_to = "value") %>%
ggplot(aes(K, value, color = metrics)) +
geom_line(size = 1.5) +
facet_wrap(~ metrics, scales = "free_y")
??pivot_longer
library(tidyr)
k_result %>%
transmute(K,
`Lower bound`         = lbound,
Residuals             = map_dbl(residual, "dispersion"),
`Semantic coherence`  = map_dbl(semantic_coherence, mean),
`Held-out likelihood` = map_dbl(eval_heldout, "expected.heldout")) %>%
pivot_longer(-K, names_to = "metrics", values_to = "value") %>%
ggplot(aes(K, value, color = metrics)) +
geom_line(size = 1.5) +
facet_wrap(~ metrics, scales = "free_y")
k_result %>%
transmute(K,
`Lower bound`         = lbound,
Residuals             = map_dbl(residual, "dispersion"),
`Semantic coherence`  = map_dbl(semantic_coherence, mean),
`Held-out likelihood` = map_dbl(eval_heldout, "expected.heldout")) %>%
pivot_longer(-K, names_to = "metrics", values_to = "value") %>%
ggplot(aes(K, value, color = metrics)) +
geom_line(size = 1.5) +
facet_wrap(~ metrics, scales = "free_y")
k_result <- models %>%
mutate(exclusivity        = map(topic_model, exclusivity),
semantic_coherence = map(topic_model, semanticCoherence, inaugural_dfm),
eval_heldout       = map(topic_model, eval.heldout, heldout$missing),
residual           = map(topic_model, checkResiduals, inaugural_dfm),
bound              = map_dbl(topic_model, function(x) max(x$convergence$bound)),
lfact              = map_dbl(topic_model, function(x) lfactorial(x$settings$dim$K)),
lbound             = bound + lfact,
iterations         = map_dbl(topic_model, function(x) length(x$convergence$bound)))
install.packages("purrr")
install.packages("purrr")
install.packages("purrr")
install.packages("purrr")
install.packages("purrr")
install.packages("purrr")
